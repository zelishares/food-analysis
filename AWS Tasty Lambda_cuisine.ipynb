{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from io import StringIO\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "ipaddress = os.environ['ipaddress']\n",
    "dbname = os.environ['dbname']\n",
    "username = os.environ['username']\n",
    "password = os.environ['password']\n",
    "port = os.environ['port']\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    tags = ['ethiopian', 'hawaiian', 'lebanese', 'swedish', 'persian', 'west_african', \n",
    "        'indigenous', 'laotian', 'venezuelan', 'kenyan', 'peruvian', 'latin_american', 'brazilian',\n",
    "        'korean', 'japanese', 'german', 'haitian', 'taiwanese', 'filipino', 'south_african',\n",
    "        'jamaican', 'american', 'bbq', 'chinese', 'french', 'caribbean', 'vietnamese', 'fusion',\n",
    "        'cuban', 'african', 'british', 'thai', 'puerto_rican', 'dominican', 'greek', 'indian',\n",
    "        'seafood', 'middle_eastern', 'mexican', 'italian', 'soul_food']\n",
    "        \n",
    "    y = {}\n",
    "    for t in tags:\n",
    "        y[t] = get_data(t)\n",
    "        y[t][\"tag\"] = t\n",
    "\n",
    "    #Eine Liste aller Dataframes erstellen\n",
    "    listOfDataframes = list(y.keys())\n",
    "    \n",
    "    # Der Loop geht über alle Keys des Dictionary und fügt die Values (Dataframes) zusammen\n",
    "    listOfKeys = []\n",
    "    for i in listOfDataframes:\n",
    "        listOfKeys.append(y[i])\n",
    "    df_total = pd.concat(listOfKeys)\n",
    "    \n",
    "    df = creat_subset(df_total)\n",
    "    \n",
    "    #enable datatype of additional_ifnormation to be in json form\n",
    "    df['topics'] = df['topics'].apply(json.dumps)\n",
    "    df['tags'] = df['tags'].apply(json.dumps)\n",
    "    df['credits'] = df['credits'].apply(json.dumps)\n",
    "    df['sections'] = df['sections'].apply(json.dumps)\n",
    "    df['instructions'] = df['instructions'].apply(json.dumps)\n",
    "    \n",
    "    # A long string that contains the necessary Postgres login information\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={}\".format(ipaddress, dbname, username, password))\n",
    "    \n",
    "    # Curser for connection\n",
    "    cur = conn.cursor()\n",
    "    engine = create_engine(\"postgresql://{}:{}@{}:5432/{}\".format(username,password,ipaddress,dbname))\n",
    "    \n",
    "    #creating table if not existent\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS tasty \\\n",
    "    (name TEXT, original_video_url TEXT, topics jsonb, keywords TEXT, tags jsonb, num_servings NUMERIC, \\\n",
    "    total_time_minutes NUMERIC, yields TEXT, country TEXT, tips_and_ratings_enabled BOOLEAN, aspect_ratio TEXT, \\\n",
    "    credits jsonb, sections jsonb, instructions jsonb, id INT, prep_time_minutes NUMERIC, description TEXT, \\\n",
    "    cook_time_minutes NUMERIC, nutrition_fiber NUMERIC, nutrition_protein NUMERIC, nutrition_fat NUMERIC, \\\n",
    "    nutrition_calories NUMERIC, nutrition_sugar NUMERIC, nutrition_carbohydrates NUMERIC, \\\n",
    "    user_ratings_count_positive NUMERIC, user_ratings_score NUMERIC, user_ratings_count_negative NUMERIC, \\\n",
    "    total_time_tier_display_tier TEXT);\")\n",
    "  \n",
    "    #adding the df into the database\n",
    "    df.to_sql('tasty', engine, if_exists = 'append', index = False)\n",
    "    \n",
    "    #delete duplicates\n",
    "    sql = \"\"\"    \n",
    "        DELETE FROM\n",
    "        tasty x\n",
    "        USING tasty y\n",
    "        WHERE\n",
    "        x.id = y.id\n",
    "        AND x.ctid > y.ctid;\n",
    "    \"\"\"\n",
    "    #cur.execute(sql)\n",
    "    \n",
    "    #close the connections\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"Data was successfully loaded into the DB.\")\n",
    "    \n",
    "\n",
    "def get_data(tag):\n",
    "    \n",
    "    # credentials for Tasty\n",
    "    headers = {\n",
    "    'x-rapidapi-host': \"tasty.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"362fc9c239mshcfe50bd2bfb56f4p1ca4e5jsncbaacdf9bb2a\"\n",
    "    }\n",
    "    \n",
    "    # query to select data from API\n",
    "    url = \"https://tasty.p.rapidapi.com/recipes/list\"\n",
    "\n",
    "    querystring = {\"from\":\"0\",\"size\":\"500\",\"tags\":tag}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    results = response.json()['results']\n",
    "    results = pd.json_normalize(results)\n",
    "    \n",
    "    # create data frame\n",
    "    df_recipes = pd.DataFrame(results)\n",
    "    \n",
    "    return df_recipes\n",
    "\n",
    "    \n",
    "def creat_subset(df):\n",
    "    \n",
    "    df = df[df['instructions'].notna()]\n",
    "    \n",
    "    # create subset\n",
    "    df = df[['name',\n",
    "     'original_video_url',\n",
    "     'topics',\n",
    "     'keywords',\n",
    "     'tags',\n",
    "     'num_servings',\n",
    "     'total_time_minutes',\n",
    "     'yields',\n",
    "     'country',\n",
    "     'tips_and_ratings_enabled',\n",
    "     'aspect_ratio',\n",
    "     'credits',\n",
    "     'sections',\n",
    "     'instructions',\n",
    "     'id',\n",
    "     'prep_time_minutes',\n",
    "     'description',\n",
    "     'cook_time_minutes',\n",
    "     'nutrition.fiber',\n",
    "     'nutrition.protein',\n",
    "     'nutrition.fat',\n",
    "     'nutrition.calories',\n",
    "     'nutrition.sugar',\n",
    "     'nutrition.carbohydrates',\n",
    "     'user_ratings.count_positive',\n",
    "     'user_ratings.score',\n",
    "     'user_ratings.count_negative',\n",
    "     'total_time_tier.display_tier']]\n",
    "     \n",
    "    df = df.rename(columns={'nutrition.fiber': 'nutrition_fiber', 'nutrition.protein': 'nutrition_protein', 'nutrition.fat': 'nutrition_fat', \\\n",
    "        'nutrition.calories': 'nutrition_calories', 'nutrition.sugar': 'nutrition_sugar', 'nutrition.carbohydrates': 'nutrition_carbohydrates', \\\n",
    "        'user_ratings.count_positive': 'user_ratings_count_positive', 'user_ratings.score': 'user_ratings_score', 'user_ratings.count_negative': 'user_ratings_count_negative', \\\n",
    "        'total_time_tier.display_tier': 'total_time_tier_display_tier'})\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
