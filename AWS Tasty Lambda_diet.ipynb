{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from io import StringIO\n",
    "import requests\n",
    "import os\n",
    "\n",
    "ipaddress = os.environ['ipaddress']\n",
    "dbname = os.environ['dbname']\n",
    "username = os.environ['username']\n",
    "password = os.environ['password']\n",
    "port = os.environ['port']\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    tags = ['best_of_tasty','low_carb','pescatarian', 'contains_alcohol', 'indulgent_sweets',\n",
    "        'healthy', 'dairy_free', 'comfort_food', 'kid_friendly', 'gluten_free', 'vegetarian', \n",
    "        'vegan']\n",
    "        \n",
    "    y = {}\n",
    "    for t in tags:\n",
    "        y[t] = get_data(t)\n",
    "        y[t][\"tag\"] = t\n",
    "\n",
    "    #Eine Liste aller Dataframes erstellen\n",
    "    listOfDataframes = list(y.keys())\n",
    "    \n",
    "    # Der Loop geht über alle Keys des Dictionary und fügt die Values (Dataframes) zusammen\n",
    "    listOfKeys = []\n",
    "    for i in listOfDataframes:\n",
    "        listOfKeys.append(y[i])\n",
    "    df_total = pd.concat(listOfKeys)\n",
    "    \n",
    "    df = clean_data(df_total)\n",
    "    \n",
    "    # A long string that contains the necessary Postgres login information\n",
    "    postgres_str = f'postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'\n",
    "    \n",
    "    # Create the connection\n",
    "    cnx = create_engine(postgres_str)\n",
    "    \n",
    "    # Load Dataframe into database\n",
    "    df.head(0).to_sql('tasty', con=cnx, index=False, if_exists='append') # head(0) uses only the header\n",
    "    # set index=False to avoid bringing the dataframe index in as a column \n",
    "    \n",
    "    raw_con = cnx.raw_connection() # assuming you set up cnx as above\n",
    "    cur  = raw_con.cursor()\n",
    "    out = StringIO()\n",
    "    \n",
    "    # write just the body of your dataframe to a csv-like file object\n",
    "    df.to_csv(out, sep='\\t', header=False, index=False) \n",
    "    \n",
    "    out.seek(0) # sets the pointer on the file object to the first line\n",
    "    contents = out.getvalue()\n",
    "    cur.copy_from(out, 'tasty', null=\"\") # copies the contents of the file object into the SQL cursor and sets null values to empty strings\n",
    "    raw_con.commit()\n",
    "    \n",
    "    #delete duplicates\n",
    "    sql = \"\"\"    \n",
    "        DELETE FROM\n",
    "        tasty x\n",
    "        USING tasty y\n",
    "        WHERE\n",
    "        x.id = y.id\n",
    "        AND x.ctid > y.ctid;\n",
    "    \"\"\"\n",
    "    with cnx.begin() as connection:     \n",
    "        connection.execute(sql)\n",
    "    \n",
    "    print(\"Data was successfully loaded into the DB.\")\n",
    "    \n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "def get_data(tag):\n",
    "    \n",
    "    # credentials for Tasty\n",
    "    headers = {\n",
    "    'x-rapidapi-host': \"tasty.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"151e12b103msha0b4622f262fc41p188e98jsn8ddd7233d384\"\n",
    "    }\n",
    "    \n",
    "    # query to select data from API\n",
    "    url = \"https://tasty.p.rapidapi.com/recipes/list\"\n",
    "\n",
    "    querystring = {\"from\":\"0\",\"size\":\"500\",\"tags\":tag}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    results = response.json()['results']\n",
    "    results = pd.json_normalize(results)\n",
    "    \n",
    "    # create data frame\n",
    "    df_recipes = pd.DataFrame(results)\n",
    "    \n",
    "    # create subset\n",
    "    df = df_recipes[['name',\n",
    "     'original_video_url',\n",
    "     'topics',\n",
    "     'keywords',\n",
    "     'tags',\n",
    "     'num_servings',\n",
    "     'total_time_minutes',\n",
    "     'yields',\n",
    "     'country',\n",
    "     'tips_and_ratings_enabled',\n",
    "     'aspect_ratio',\n",
    "     'credits',\n",
    "     'sections',\n",
    "     'instructions',\n",
    "     'id',\n",
    "     'prep_time_minutes',\n",
    "     'description',\n",
    "     'cook_time_minutes',\n",
    "     'nutrition.fiber',\n",
    "     'nutrition.protein',\n",
    "     'nutrition.fat',\n",
    "     'nutrition.calories',\n",
    "     'nutrition.sugar',\n",
    "     'nutrition.carbohydrates',\n",
    "     'user_ratings.count_positive',\n",
    "     'user_ratings.score',\n",
    "     'user_ratings.count_negative',\n",
    "     'total_time_tier.display_tier']]\n",
    "     \n",
    "    df = df.rename(columns={'nutrition.fiber': 'nutrition_fiber', 'nutrition.protein': 'nutrition_protein', 'nutrition.fat': 'nutrition_fat', \\\n",
    "        'nutrition.calories': 'nutrition_calories', 'nutrition.sugar': 'nutrition_sugar', 'nutrition.carbohydrates': 'nutrition_carbohydrates', \\\n",
    "        'user_ratings.count_positive': 'user_ratings_count_positive', 'user_ratings.score': 'user_ratings_score', 'user_ratings.count_negative': 'user_ratings_count_negative', \\\n",
    "        'total_time_tier.display_tier': 'total_time_tier_display_tier'})\n",
    "    \n",
    "    # fillna\n",
    "    df.fillna(0)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "def clean_data(df):\n",
    "    \n",
    "    df = df[df['instructions'].notna()]\n",
    "    \n",
    "    for index_label, row_series in df.iterrows():\n",
    "        l = []\n",
    "        for i in row_series['topics']:\n",
    "            l.append(i['name'])\n",
    "        df.at[index_label , 'topics_clean'] = ', '.join([str(item) for item in l])\n",
    "        \n",
    "    for index_label, row_series in df.iterrows():\n",
    "        l = []\n",
    "        for i in row_series['tags']:\n",
    "            l.append(i['name'])\n",
    "        df.at[index_label , 'tags_clean'] = ', '.join([str(item) for item in l])\n",
    "        \n",
    "    for index_label, row_series in df.iterrows():\n",
    "        l = []\n",
    "        for i in row_series['credits']:\n",
    "            l.append(i['type'])\n",
    "        # only the first value as we need only one value per entry    \n",
    "        df.at[index_label , 'credits_clean'] = l[0]\n",
    "        \n",
    "    for index_label, row_series in df.iterrows():\n",
    "        l = []\n",
    "        for i in row_series['instructions']:\n",
    "            l.append(i['display_text'])\n",
    "        df.at[index_label , 'instructions_clean'] = ', '.join([str(item) for item in l])\n",
    "        \n",
    "    for index_label, row_series in df.iterrows():\n",
    "        l = []\n",
    "        for i in row_series['sections']:\n",
    "            for j in i['components']:\n",
    "                l.append(j['raw_text'])\n",
    "        df.at[index_label , 'ingredients'] = ', '.join([str(item) for item in l])\n",
    "        \n",
    "    df.drop(['topics', 'tags', 'credits', 'instructions', 'sections'], axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
